{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import datetime\n",
    "import holidays\n",
    "import numpy as np\n",
    "\n",
    "# Function to generate a DataFrame with missing rows added\n",
    "def fill_missing_values(file_path, sheet_name=None):\n",
    "    # Read the Excel file\n",
    "    if sheet_name:\n",
    "        df = pd.read_excel(file_path, sheet_name=sheet_name, header=4)  # Set the fifth row as the header\n",
    "    else:\n",
    "        df = pd.read_excel(file_path, header=4)  # Set the fifth row as the header\n",
    "\n",
    "    # Print column names to verify\n",
    "    print(\"Columns:\", df.columns)\n",
    "\n",
    "    # Access 'Date' column by index (assumed to be the first column) and convert to date\n",
    "    date_column_index = 0\n",
    "    value_column_index = 2  # Third column contains the values\n",
    "\n",
    "    df.iloc[:, date_column_index] = pd.to_datetime(df.iloc[:, date_column_index], format='%d.%m.%y').dt.date\n",
    "\n",
    "    # Create a DataFrame with only the Date and Value columns\n",
    "    df = df.iloc[:, [date_column_index, value_column_index]]\n",
    "    df.columns = ['Date', 'Value']\n",
    "\n",
    "    # Set 'Date' as the index for easier manipulation\n",
    "    df.set_index('Date', inplace=True)\n",
    "\n",
    "    # Create a complete range of daily dates between the min and max Date\n",
    "    full_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq='D').date\n",
    "\n",
    "    # Reindex the DataFrame to include all dates in the range\n",
    "    df = df.reindex(full_range)\n",
    "\n",
    "    # Print missing dates\n",
    "    missing_dates = df[df['Value'].isna()].index\n",
    "    for missing_date in missing_dates:\n",
    "        print(f\"Missing date found: {missing_date}\")\n",
    "\n",
    "    # Reset the index and fill missing 'Value' entries with NaN\n",
    "    df.reset_index(inplace=True)\n",
    "    df.columns = ['Date', 'Value']\n",
    "\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process all data as Downloaded from LUIS (Environmental data tool city of Graz)\n",
    "http://app.luis.steiermark.at/luft2/suche.php?station1=&station2=&komponente1=&station3=&station4=&komponente2=&von_tag=1&von_monat=1&von_jahr=2009&mittelwert=21&bis_tag=31&bis_monat=12&bis_jahr=2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strRelPathToDownloads = \"../datasets/raw_2009-2013/downloads\"\n",
    "strRelPathOutput = \"../datasets/raw_2009-2013/processed\"\n",
    "\n",
    "liFiles = os.listdir(strRelPathToDownloads)\n",
    "\n",
    "for strFile in liFiles:\n",
    "    strFilePath = os.path.join(strRelPathToDownloads,strFile)\n",
    "    sheet_name = None\n",
    "    filled_df = fill_missing_values(strFilePath, sheet_name)\n",
    "    filled_df.to_excel(os.path.join(strRelPathOutput,\"PRO_\"+strFile), index=False)\n",
    "    print(f\"Filled DataFrame saved to {strFilePath}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy manually all columns (station by station) and store it into data_per_station_2009-2013"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define dictionary containing all station dataframes and read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>pm10</th>\n",
       "      <th>rh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-02</th>\n",
       "      <td>-5.822104</td>\n",
       "      <td>76.490000</td>\n",
       "      <td>86.730840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-03</th>\n",
       "      <td>-4.172874</td>\n",
       "      <td>53.750000</td>\n",
       "      <td>90.160835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-04</th>\n",
       "      <td>-4.812709</td>\n",
       "      <td>62.070007</td>\n",
       "      <td>85.871666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-05</th>\n",
       "      <td>-6.369397</td>\n",
       "      <td>89.330025</td>\n",
       "      <td>82.762090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-06</th>\n",
       "      <td>-3.787598</td>\n",
       "      <td>112.439964</td>\n",
       "      <td>79.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-27</th>\n",
       "      <td>7.975574</td>\n",
       "      <td>19.289993</td>\n",
       "      <td>87.726460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-28</th>\n",
       "      <td>6.086780</td>\n",
       "      <td>18.250000</td>\n",
       "      <td>90.061180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-29</th>\n",
       "      <td>2.726640</td>\n",
       "      <td>22.150010</td>\n",
       "      <td>94.296364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-30</th>\n",
       "      <td>3.986715</td>\n",
       "      <td>18.229994</td>\n",
       "      <td>90.518394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31</th>\n",
       "      <td>4.210825</td>\n",
       "      <td>26.380003</td>\n",
       "      <td>90.447290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1825 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                temp        pm10         rh\n",
       "2009-01-02 -5.822104   76.490000  86.730840\n",
       "2009-01-03 -4.172874   53.750000  90.160835\n",
       "2009-01-04 -4.812709   62.070007  85.871666\n",
       "2009-01-05 -6.369397   89.330025  82.762090\n",
       "2009-01-06 -3.787598  112.439964  79.990000\n",
       "...              ...         ...        ...\n",
       "2013-12-27  7.975574   19.289993  87.726460\n",
       "2013-12-28  6.086780   18.250000  90.061180\n",
       "2013-12-29  2.726640   22.150010  94.296364\n",
       "2013-12-30  3.986715   18.229994  90.518394\n",
       "2013-12-31  4.210825   26.380003  90.447290\n",
       "\n",
       "[1825 rows x 3 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_df_stations_2009_2013 = {'d':pd.DataFrame(),'w':pd.DataFrame(),'s':pd.DataFrame(),'n':pd.DataFrame(),'e':pd.DataFrame()}\n",
    "\n",
    "for strKey in dict_df_stations_2009_2013:\n",
    "    dict_df_stations_2009_2013[strKey] = pd.read_excel(\"../datasets/data_per_station_2009-2013/\"+strKey+\".xls\",index_col=0)  # Set the fifth row as the header\n",
    "dict_df_stations_2009_2013['d']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions needed to add temporal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# the below is the same, but takes a string:\n",
    "at_holidays = holidays.country_holidays(subdiv='6',country=\"AT\")\n",
    "hr_holidays = holidays.country_holidays(country=\"HR\")\n",
    "def check_holiday(date,country_hol)->int:\n",
    "    if date in country_hol:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "def check_weekend(date)->int:\n",
    "    if date.weekday() > 4: #goes from 0..6\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_day_of_year(date):\n",
    "    return date.timetuple().tm_yday\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add temporal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dict_df_stations_2009_2013:  \n",
    "    dict_df_stations_2009_2013[df][\"dayOfYear\"] =  [get_day_of_year(date) for date in dict_df_stations_2009_2013[df].index.to_pydatetime()]\n",
    "    dict_df_stations_2009_2013[df][\"holiday\"] =  [check_holiday(date,at_holidays) for date in dict_df_stations_2009_2013[df].index]\n",
    "    dict_df_stations_2009_2013[df][\"dayAfterHoliday\"] =  [check_holiday(date-datetime.timedelta(days=1),at_holidays) for date in dict_df_stations_2009_2013[df].index]\n",
    "    dict_df_stations_2009_2013[df][\"dayBeforeHoliday\"] =  [check_holiday(date+datetime.timedelta(days=1),at_holidays) for date in dict_df_stations_2009_2013[df].index]\n",
    "    dict_df_stations_2009_2013[df][\"weekend\"] =  [check_weekend(date) for date in dict_df_stations_2009_2013[df].index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add pm10 lag values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dict_df_stations_2009_2013:  \n",
    "    dict_df_stations_2009_2013[df][\"pm10Lag\"] = dict_df_stations_2009_2013[df][\"pm10\"].shift(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop data annually 1st to 3rd January (New year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_drop_dates_new_year = ['01-01', '01-02','01-03']\n",
    "\n",
    "for df in dict_df_stations_2009_2013:  \n",
    "    # uncomment to see all values to be dropped\n",
    "    #print(\"New year values\")\n",
    "    #display(dict_df_stations[df][dict_df_stations[df].index.strftime('%m-%d').isin(li_drop_dates_new_year)])\n",
    "\n",
    "    index_to_drop_graz = dict_df_stations_2009_2013[df][dict_df_stations_2009_2013[df].index.strftime('%m-%d').isin(li_drop_dates_new_year)].index\n",
    "    dict_df_stations_2009_2013[df].drop(index_to_drop_graz,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find NaN values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: temp count:  18\n",
      "Feature: pm10 count:  26\n",
      "Feature: rh count:  1\n",
      "Feature: pm10Lag count:  26\n",
      "Total NaN:  71\n"
     ]
    }
   ],
   "source": [
    "def calc_output_nans(df):\n",
    "    total_nan = 0\n",
    "    for elem in list(df.keys()):\n",
    "        length = len(df.loc[df[elem].isnull(),])\n",
    "        total_nan += length\n",
    "        if length > 0:\n",
    "            print(\"Feature: \"+ elem, \"count: \",length)\n",
    "    print(\"Total NaN: \",total_nan)\n",
    "\n",
    "\n",
    "calc_output_nans(dict_df_stations_2009_2013[\"d\"])\n",
    "#calc_output_nans(dict_df_stations_2009_2013[\"e\"])\n",
    "#calc_output_nans(dict_df_stations_2009_2013[\"n\"])\n",
    "#calc_output_nans(dict_df_stations_2009_2013[\"s\"])\n",
    "#calc_output_nans(dict_df_stations_2009_2013[\"w\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find rows in which NaN values occur - important to know how many instance contain NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of total NAs:  2056\n"
     ]
    }
   ],
   "source": [
    "def checkNaN(dict_df,detailed=True):\n",
    "    li_stations = [\"d\",\"n\",\"e\",\"s\",\"w\"]\n",
    "    total_nas = 0\n",
    "    for station in dict_df:\n",
    "        df = dict_df[station]\n",
    "        #print(dict_df_stations_2009_2013[station])\n",
    "        total_nas += len(df[df.isna().any(axis=1)])\n",
    "        #print(\"No. of NAs: \",len(df[df.isna().any(axis=1)]))\n",
    "    \n",
    "        if detailed:\n",
    "            display(df[df.isna().any(axis=1)])\n",
    "    print(\"No. of total NAs: \",total_nas)\n",
    "\n",
    "checkNaN(dict_df_stations_2009_2013,False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Station east no temp, hum, press\n",
    "# imputed from nearby station south\n",
    "dict_df_stations_2009_2013[\"e\"][[\"temp\"]] = dict_df_stations_2009_2013[\"s\"][[\"temp\"]]\n",
    "dict_df_stations_2009_2013[\"e\"][[\"rh\"]] = dict_df_stations_2009_2013[\"s\"][[\"rh\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check NaN again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of total NAs:  291\n"
     ]
    }
   ],
   "source": [
    "checkNaN(dict_df_stations_2009_2013,False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 291 NaN instances (rows in which a NaN value occurs) \n",
    "\n",
    "- 1825 instances per station --> 5 *1825 = 9125 total instances\n",
    "\n",
    "- 291 / 9125 = 0.0318 --> 3.1% of NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,df in dict_df_stations_2009_2013.items():\n",
    "    filepath = Path('../datasets/data_per_station_2009-2013/'+name+'.csv')\n",
    "    dict_df_stations_2009_2013[name].to_csv(filepath,sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from 2014-2021, concat with 2009-2013, while only using similiar features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rh</th>\n",
       "      <th>dayOfYear</th>\n",
       "      <th>dayBeforeHoliday</th>\n",
       "      <th>pm10</th>\n",
       "      <th>weekend</th>\n",
       "      <th>holiday</th>\n",
       "      <th>pm10Lag</th>\n",
       "      <th>temp</th>\n",
       "      <th>dayAfterHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-04</th>\n",
       "      <td>85.871666</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>62.070007</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.750000</td>\n",
       "      <td>-4.812709</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-05</th>\n",
       "      <td>82.762090</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>89.330025</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62.070007</td>\n",
       "      <td>-6.369397</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-06</th>\n",
       "      <td>79.990000</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>112.439964</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>89.330025</td>\n",
       "      <td>-3.787598</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-07</th>\n",
       "      <td>87.087910</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>80.979990</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112.439964</td>\n",
       "      <td>-4.472021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-01-08</th>\n",
       "      <td>85.682060</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>86.800026</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.979990</td>\n",
       "      <td>-4.773334</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-21</th>\n",
       "      <td>95.958333</td>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>27.362500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28.837500</td>\n",
       "      <td>2.754167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-22</th>\n",
       "      <td>95.083333</td>\n",
       "      <td>326</td>\n",
       "      <td>0</td>\n",
       "      <td>31.566667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.362500</td>\n",
       "      <td>4.316667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-23</th>\n",
       "      <td>91.000000</td>\n",
       "      <td>327</td>\n",
       "      <td>0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.566667</td>\n",
       "      <td>3.791667</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-24</th>\n",
       "      <td>87.500000</td>\n",
       "      <td>328</td>\n",
       "      <td>0</td>\n",
       "      <td>38.900000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.654167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-11-25</th>\n",
       "      <td>92.625000</td>\n",
       "      <td>329</td>\n",
       "      <td>0</td>\n",
       "      <td>45.112500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38.900000</td>\n",
       "      <td>0.070833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4668 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   rh  dayOfYear  dayBeforeHoliday        pm10  weekend  \\\n",
       "2009-01-04  85.871666          4                 0   62.070007        1   \n",
       "2009-01-05  82.762090          5                 1   89.330025        0   \n",
       "2009-01-06  79.990000          6                 0  112.439964        0   \n",
       "2009-01-07  87.087910          7                 0   80.979990        0   \n",
       "2009-01-08  85.682060          8                 0   86.800026        0   \n",
       "...               ...        ...               ...         ...      ...   \n",
       "2021-11-21  95.958333        325                 0   27.362500        1   \n",
       "2021-11-22  95.083333        326                 0   31.566667        0   \n",
       "2021-11-23  91.000000        327                 0   33.000000        0   \n",
       "2021-11-24  87.500000        328                 0   38.900000        0   \n",
       "2021-11-25  92.625000        329                 0   45.112500        0   \n",
       "\n",
       "            holiday     pm10Lag      temp  dayAfterHoliday  \n",
       "2009-01-04        0   53.750000 -4.812709                0  \n",
       "2009-01-05        0   62.070007 -6.369397                0  \n",
       "2009-01-06        1   89.330025 -3.787598                0  \n",
       "2009-01-07        0  112.439964 -4.472021                1  \n",
       "2009-01-08        0   80.979990 -4.773334                0  \n",
       "...             ...         ...       ...              ...  \n",
       "2021-11-21        0   28.837500  2.754167                0  \n",
       "2021-11-22        0   27.362500  4.316667                0  \n",
       "2021-11-23        0   31.566667  3.791667                0  \n",
       "2021-11-24        0   33.000000  0.654167                0  \n",
       "2021-11-25        0   38.900000  0.070833                0  \n",
       "\n",
       "[4668 rows x 9 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_df_stations_2014_2021 = {'d':pd.DataFrame(),'w':pd.DataFrame(),'s':pd.DataFrame(),'n':pd.DataFrame(),'e':pd.DataFrame()}\n",
    "\n",
    "dict_df_stations_total = {'d':pd.DataFrame(),'w':pd.DataFrame(),'s':pd.DataFrame(),'n':pd.DataFrame(),'e':pd.DataFrame()}\n",
    "\n",
    "station_id = 0\n",
    "for strKey in dict_df_stations_2014_2021:\n",
    "    dict_df_stations_2014_2021[strKey] = pd.read_csv(\"../datasets/data_per_station/\"+strKey+\".csv\",index_col=0,parse_dates=True)  # Set the fifth row as the header\n",
    "    dict_df_stations_2009_2013[strKey] = pd.read_csv(\"../datasets/data_per_station_2009-2013/\"+strKey+\".csv\",index_col=0,parse_dates=True)  # Set the fifth row as the header\n",
    "\n",
    "    # get common features\n",
    "    station_id = dict_df_stations_2014_2021[strKey][\"id\"]\n",
    "    liFeatures_2014_2021 = dict_df_stations_2014_2021[strKey].columns.to_list()\n",
    "    liFeatures_2009_2013 = dict_df_stations_2009_2013[strKey].columns.to_list()\n",
    "    liCommonFeatures = list(set(liFeatures_2014_2021) & set(liFeatures_2009_2013))\n",
    "\n",
    "    # concat to one large dataframe\n",
    "    dict_df_stations_total[strKey] = dfConCat = pd.concat([dict_df_stations_2009_2013[strKey][liCommonFeatures],dict_df_stations_2014_2021[strKey][liCommonFeatures]])\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the length of the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station:  d 4668\n",
      "Station:  w 4668\n",
      "Station:  s 4668\n",
      "Station:  n 4668\n",
      "Station:  e 4668\n",
      "Total rows:  23340\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for station in dict_df_stations_total:\n",
    "    cnt += len(dict_df_stations_total[station]) \n",
    "    print(\"Station: \",station,len(dict_df_stations_total[station]))\n",
    "print(\"Total rows: \",cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,df in dict_df_stations_total.items():\n",
    "    filepath = Path('../datasets/data_per_station_2009-2022/'+name+'.csv')\n",
    "    dict_df_stations_total[name].to_csv(filepath,sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PMForecastingVenV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
