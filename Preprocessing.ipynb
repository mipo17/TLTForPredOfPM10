{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e7370568-9f62-4476-9bf7-557705067624",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import datetime\n",
    "import holidays\n",
    "import numpy as np\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebc7bc6-70de-48ce-a824-cb78e651bfc3",
   "metadata": {},
   "source": [
    "# Control pre-processing \n",
    " - define whether to drop rows (only after expl. data analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "78628bff-2c1e-4e95-a041-d9014f13f5f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_graz_sahara_measurements = True\n",
    "drop_graz_newYear_measurements = True\n",
    "\n",
    "drop_zagreb_sahara_measurements = True\n",
    "drop_zagreb_newYear_measurements = True\n",
    "\n",
    "add_lag_values = True\n",
    "\n",
    "dayOfYearSinusFunction = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accbce99-8caa-4b8b-9ed0-c72f24ae9b21",
   "metadata": {},
   "source": [
    "### define functions used for adding features in both data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "237077e9-24fe-44d4-97dc-fb37b63f84fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# the below is the same, but takes a string:\n",
    "at_holidays = holidays.country_holidays(subdiv='6',country=\"AT\")\n",
    "hr_holidays = holidays.country_holidays(country=\"HR\")\n",
    "def check_holiday(date,country_hol)->int:\n",
    "    if date in country_hol:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "def check_weekend(date)->int:\n",
    "    if date.weekday() > 4: #goes from 0..6\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_day_of_year(date):\n",
    "    return date.timetuple().tm_yday\n",
    "\n",
    "\n",
    "# Function to get the day of the year dynamically considering leap years\n",
    "def get_day_of_year_adjusted(date):\n",
    "    year = date.year\n",
    "    days_in_year = 366 if calendar.isleap(year) else 365\n",
    "    return date.timetuple().tm_yday, days_in_year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b38d06-abf8-420b-bd5c-bbbed9392e6f",
   "metadata": {},
   "source": [
    "# Pre-process data from Zagreb\n",
    " - read \n",
    " - rename variables (columns) -> done in excel sheet\n",
    " - replace/write C with/in ene\n",
    " - delete NEE since it is always 0 -> after that there are 16 categories (which is the norm)\n",
    " - save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e1676b60-4646-42d0-a8b3-03082bd08478",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_excel_file(path,col_names=None) -> pd.DataFrame:\n",
    "    data_dict = pd.read_excel(path,\n",
    "                sheet_name=None,\n",
    "                index_col=0,\n",
    "                header=0,\n",
    "                names=col_names,\n",
    "                parse_dates=[0])\n",
    "    return data_dict[list(data_dict.keys())[0]]\n",
    "\n",
    "filepath = Path('../datasets/data_zagreb.xlsx')\n",
    "\n",
    "col_names_zagreb = ['z_pm10', 'z_pm2.5', 'z_pm1', 'year', 'z_tempMax', 'z_tempMin', 'z_temp',\n",
    "                   'z_tempMax-min', 'z_pressureMax', 'z_pressureMin', 'z_pressure', 'z_pressurePmax-min', 'z_rhMax',\n",
    "                   'z_rh_min', 'z_rh', 'z_rh_max-min', 'z_windsp', 'z_precip',\n",
    "                   \"n\",\"nne\",\"ne\",\"ene\",\"e\",\"ese\", \"se\", \"sse\",\"s\",\"ssw\",\"sw\",\"wsw\",\"w\",\"wnw\",\"nw\",\"nnw\",'nee','c']\n",
    "\n",
    "\n",
    "df_zagreb = read_excel_file(filepath,col_names_zagreb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793305f6-07d8-4ac9-a2ca-99b043f81024",
   "metadata": {},
   "source": [
    "## replace/write C with/in ene AND delete col c\n",
    "## replace nee with ene (there is only one nee value: 2013-03-14) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6955324f-f7f5-4c12-839a-9c5e0358111b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_zagreb.loc[df_zagreb['c'] == 1, 'ene'] = 1\n",
    "df_zagreb.drop('c', inplace=True, axis=1)\n",
    "\n",
    "df_zagreb.loc[df_zagreb['nee'] == 1, 'ene'] = 1\n",
    "df_zagreb.drop('nee', inplace=True, axis=1)\n",
    "\n",
    "df_zagreb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b9437a0f-b3e8-4626-940c-abc9abac87a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_wind_dir_list(df) -> list:\n",
    "    \"\"\"\n",
    "    creates a list of wind directions e.g. 1->e, 2->ene,...\n",
    "    \"\"\"\n",
    "    # in this order the columns occur in the sheet\n",
    "    li_wind_key = [\"n\",\"nne\",\"ne\",\"ene\",\"e\",\"ese\", \"se\", \"sse\",\"s\",\"ssw\",\"sw\",\"wsw\",\"w\",\"wnw\",\"nw\",\"nnw\"]\n",
    "\n",
    "    li_wind_val = list(range(1,17))\n",
    "    dict_wind_dir = dict(zip(li_wind_key, li_wind_val))\n",
    "    li_wind_dir_category = []\n",
    "    for index, row in df.iterrows():\n",
    "        found = False\n",
    "        for key,value in dict_wind_dir.items():\n",
    "            if row[key] == 1:\n",
    "                li_wind_dir_category.append(value)\n",
    "                found=True\n",
    "        if found==False:\n",
    "            print(row)\n",
    "    return li_wind_dir_category\n",
    "\n",
    "def wind_class_to_degree(w_class_number) -> float:\n",
    "    li_wind_key = [\"n\",\"nne\",\"ne\",\"ene\",\"e\",\"ese\", \"se\", \"sse\",\"s\",\"ssw\",\"sw\",\"wsw\",\"w\",\"wnw\",\"nw\",\"nnw\"]\n",
    "    w_class = li_wind_key[w_class_number-1]\n",
    "    dict_degs = {'n': 0,\n",
    "            'nne': 22.5,\n",
    "            'ne': 45,\n",
    "            'ene': 67.5,\n",
    "            'e': 90,\n",
    "            'ese': 112.5,\n",
    "            'se': 135,\n",
    "            'sse': 157.5,\n",
    "            's': 180,\n",
    "            'ssw': 202.5,\n",
    "            'sw': 225,\n",
    "            'wsw': 247.5,\n",
    "            'w': 270,\n",
    "            'wnw': 292.5,\n",
    "            'nw': 315,\n",
    "            'nnw': 337.5}\n",
    "    return dict_degs[w_class]\n",
    "\n",
    "li_calc_class = create_wind_dir_list(df_zagreb)\n",
    "li_calc_degree = [wind_class_to_degree(elem) for elem in li_calc_class]\n",
    "# add new column and fill with values\n",
    "df_zagreb.insert(17, \"z_windDirClass\",li_calc_class)\n",
    "df_zagreb.insert(18, \"z_windDirDeg\",li_calc_degree)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96abf104-2ca0-477c-8e43-90eb7fa702a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Add features:\n",
    " - day of year\n",
    " - isholiday\n",
    " - dayBeforH\n",
    " - dayAfterH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "eadb8785-a62a-400c-8f01-90c4adea422d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# OLD without sin transformation\n",
    "if dayOfYearSinusFunction:\n",
    "    df_zagreb[\"dayOfYear\"] = [\n",
    "    np.sin(2 * np.pi * get_day_of_year_adjusted(date)[0] / get_day_of_year_adjusted(date)[1])\n",
    "    for date in df_zagreb.index.to_pydatetime()\n",
    "]\n",
    "else:\n",
    "    df_zagreb[\"dayOfYear\"] =  [get_day_of_year(date) for date in df_zagreb.index.to_pydatetime()]\n",
    "\n",
    "\n",
    "df_zagreb[\"holiday\"] =  [check_holiday(date,hr_holidays) for date in df_zagreb.index]\n",
    "df_zagreb[\"dayAfterHoliday\"] =  [check_holiday(date-datetime.timedelta(days=1),hr_holidays) for date in df_zagreb.index]\n",
    "df_zagreb[\"dayBeforeHoliday\"] =  [check_holiday(date+datetime.timedelta(days=1),hr_holidays) for date in df_zagreb.index]\n",
    "df_zagreb[\"weekend\"] =  [check_weekend(date) for date in df_zagreb.index]\n",
    "if add_lag_values:\n",
    "    df_zagreb[\"pm10Lag\"] = df_zagreb[\"z_pm10\"].shift(1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8085b29c-1269-4c40-9e1f-63ffeab3b4c1",
   "metadata": {},
   "source": [
    "## Define a function to output nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "900c0499-441d-4f0d-869d-3e70405ef084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_output_nans(df):\n",
    "    total_nan = 0\n",
    "    for elem in list(df.keys()):\n",
    "        length = len(df.loc[df[elem].isnull(),])\n",
    "        total_nan += length\n",
    "        if length > 0:\n",
    "            print(\"Feature: \"+ elem, length)\n",
    "    print(\"Total NaN: \",total_nan)\n",
    "\n",
    "calc_output_nans(df_zagreb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916eceed-4650-4e1f-9f60-96aba8847e87",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Drop data from 24th to 28th March (Sahara Dust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f062eb37-f4df-4ec9-87b1-3416ab914a49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "print(\"Sahara dust values\")\n",
    "display(df_zagreb[(df_zagreb.index >= \"2020-03-24\") & (df_zagreb.index <= \"2020-03-28\")])\n",
    "\n",
    "index_to_drop_zagreb = df_zagreb[(df_zagreb.index >= \"2020-03-24\") & (df_zagreb.index <= \"2020-03-28\")].index\n",
    "\n",
    "if drop_zagreb_sahara_measurements:\n",
    "    print(\"******************************\\nDrop Sahara measurements\\n******************************\")\n",
    "    df_zagreb.drop(index_to_drop_zagreb,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b05008b-6b9a-43ea-80ff-b7a4fb23c069",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Drop data annually 1st to 3rd January (New year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e21123-b299-47ea-973a-a9eec504bcc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "li_drop_dates_new_year = ['01-01', '01-02','01-03']\n",
    "\n",
    "print(\"New year values\")\n",
    "display(df_zagreb[df_zagreb.index.strftime('%m-%d').isin(li_drop_dates_new_year)])\n",
    "\n",
    "index_to_drop_zagreb = df_zagreb[df_zagreb.index.strftime('%m-%d').isin(li_drop_dates_new_year)].index\n",
    "\n",
    "if drop_zagreb_newYear_measurements:\n",
    "    print(\"******************************\\nDrop NewYear measurements\\n******************************\")\n",
    "    df_zagreb.drop(index_to_drop_zagreb,inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e236025-ac83-4551-aaec-26c01f676ba3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save pre-processed data from Zagreb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f21b7db4-e51b-4505-b409-11ae1fc95390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath = Path('../datasets/data_zagreb_preprocessed.csv')  \n",
    "\n",
    "# uncomment to save\n",
    "#df_zagreb.to_csv(filepath,sep=',')  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce9988b-9db1-4ac0-a296-663c4dce7ad5",
   "metadata": {},
   "source": [
    "# Select desired features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510f7ca4-484f-490a-bd26-add9c781c3e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if add_lag_values:\n",
    "    df_zagreb = df_zagreb[['z_pm10', 'z_pm2.5', 'z_pm1', 'year',\n",
    "           'z_temp','z_pressure', 'z_rh','z_windsp', 'z_windDirClass', 'z_windDirDeg',\n",
    "           'z_precip', 'dayOfYear', 'holiday','dayAfterHoliday', 'dayBeforeHoliday', 'weekend',\"pm10Lag\"]]\n",
    "else:\n",
    "     df_zagreb = df_zagreb[['z_pm10', 'z_pm2.5', 'z_pm1', 'year',\n",
    "           'z_temp','z_pressure', 'z_rh','z_windsp', 'z_windDirClass', 'z_windDirDeg',\n",
    "           'z_precip', 'dayOfYear', 'holiday','dayAfterHoliday', 'dayBeforeHoliday', 'weekend']]\n",
    "    \n",
    "df_zagreb.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f86ceb-0301-4733-91ff-739814ab057f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5fb0c153-d189-4115-a836-56a39919f517",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rename_columns(df)->pd.DataFrame:\n",
    "    li_col_names = df.columns\n",
    "    li_new_names = [elem.split('_')[1] if len(elem.split('_'))>1 else elem for elem in li_col_names]\n",
    "    \n",
    "    dict_rename = dict(zip(li_col_names,li_new_names))\n",
    "    return  df.rename(columns=dict_rename)\n",
    "\n",
    "df_zagreb = rename_columns(df_zagreb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b774a681-82c0-4b0e-bf80-ec1d5a3600ff",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Save pre-processed data from Zagreb as done per Station in Graz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "14281463-1aa3-4ba1-9f0f-f7a8eae5f0ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath_zagreb = Path('../datasets/data_per_station/z.csv')\n",
    "\n",
    "# uncomment to save\n",
    "df_zagreb.to_csv(filepath_zagreb,sep=',') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c734c45c-e9bd-4c68-8e4e-fe7f70be75e2",
   "metadata": {},
   "source": [
    "# Pre-process data from Graz\n",
    " - read \n",
    " - rename variables (columns) -> done in excel sheet\n",
    " - replace/write C with/in ene\n",
    " - delete NEE since it is always 0 -> after that there are 16 categories (which is the norm)\n",
    " - save as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "aca3066d-f92e-41ca-a708-1674f09ae4c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filepath_graz_met = Path('../datasets/data_graz_meteorology.csv')\n",
    "filepath_graz_pol = Path('../datasets/data_graz_air_pollutants.csv')\n",
    "\n",
    "def read_csv_data(path,col_names=None) -> pd.DataFrame:\n",
    "    ts = pd.read_csv(path,\n",
    "        header=0,\n",
    "        names=col_names,\n",
    "        index_col=0,\n",
    "        infer_datetime_format=True,\n",
    "        parse_dates=[0]) #to set index to datetime\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "d9701a77-d201-435e-bfde-92edbe348c00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "col_names_met = ['d_temp', 'd_rh', 'n_temp', 'n_rh', 'n_pressure',\n",
    "       'n_precip', 'n_radiation', 'n_windDirDeg', 'n_windsp',\n",
    "       'n_windPeak', 'e_temp', 'e_rh', 'e_pressure',\n",
    "       'e_windDirDeg', 'e_windsp', 'e_windPeak', 's_temp',\n",
    "       's_rh', 's_windDirDeg', 's_windsp', 's_windPeak',\n",
    "       'w_temp', 'w_rh', 'w_windDirDeg', 'w_windsp',\n",
    "       'w_windPeak']\n",
    "col_names_pol = ['d_no', 'd_no2', 'd_nox', 'd_pm10', 'n_o3', 'n_no', 'n_no2', 'n_nox',\n",
    "       'n_pm10', 'e_no', 'e_no2', 'e_nox', 'e_pm10', 's_o3', 's_no', 's_no2',\n",
    "       's_nox', 's_pm10', 'w_no', 'w_no2', 'w_nox', 'w_pm10']\n",
    "df_graz_met = read_csv_data(filepath_graz_met,col_names_met)\n",
    "df_graz_pol = read_csv_data(filepath_graz_pol,col_names_pol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bebadcc-3256-4dcf-9bd3-7ef820191b48",
   "metadata": {},
   "source": [
    "calc wind direction degrees into classes:\n",
    "https://www.surfertoday.com/windsurfing/how-to-read-wind-direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e0a6a112-03e6-49a3-b46a-aeb70db5dca7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def degToCategorical(num,li_str):\n",
    "    index=int((int(num)/22.5)+0.5)\n",
    "    li = list(range(0,17))\n",
    "    if li_str:\n",
    "        li=[\"n\",\"nne\",\"ne\",\"ene\",\"e\",\"ese\", \"se\", \"sse\",\"s\",\"ssw\",\"sw\",\"wsw\",\"w\",\"wnw\",\"nw\",\"nnw\"]\n",
    "    return li[(index % 16)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7f302b-4ad7-433e-a9a7-6980f215341e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_graz_met.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04625fd1-3517-4105-b4c1-1c98997e52e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(degToCategorical(348,True))\n",
    "#int(154.7/22.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdab706-0a01-4bbc-8e34-e29688e4c466",
   "metadata": {},
   "source": [
    "### Add column wind directions classes, which are calculated of wind direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "6a66ccec-95fc-4ced-9aeb-c76232669b5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "for winddirdeg,winddirclass in [('n_windDirDeg','n_windDirClass'),('e_windDirDeg','e_windDirClass'),('s_windDirDeg','s_windDirClass'),('w_windDirDeg','w_windDirClass')]:\n",
    "    df_graz_met[winddirclass] = df_graz_met[winddirdeg].apply(lambda x: degToCategorical(x,False) if not math.isnan(x) else x)\n",
    "\n",
    "# first change fill nan values with -99 to cast column into int -> not possible with NaN\n",
    "df_graz_met = df_graz_met.fillna(-99)\n",
    "\n",
    "for elem in ['n_windDirClass','e_windDirClass','s_windDirClass','w_windDirClass']:\n",
    "       df_graz_met[elem] = df_graz_met[elem].astype(int)\n",
    " \n",
    "\n",
    "df_graz_met.replace(-99.000000,np.nan,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab8e679-a6c8-4d3d-8a31-9d3f00b88a5f",
   "metadata": {},
   "source": [
    "## Define a function to output nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb9b7f8-1c63-447b-9454-3bd17700dcfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_output_nans(df):\n",
    "    total_nan = 0\n",
    "    for elem in list(df.keys()):\n",
    "        length = len(df.loc[df[elem].isnull(),])\n",
    "        total_nan += length\n",
    "        if length > 0:\n",
    "            print(\"Feature: \"+ elem, length)\n",
    "    print(\"Total NaN: \",total_nan)\n",
    "\n",
    "calc_output_nans(df_graz_pol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddece5f-b1f1-400b-9b44-290e767efc22",
   "metadata": {},
   "source": [
    "## Impute empty temperature,pressure,humidity values with the mean temperature of the remaining stations: \n",
    " - calc if depending on the values, if none value do not count that stations. sum/n -> n depends on how many none NaN values exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cb5526-c9d8-44d2-89ee-b81ee8c59b53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "calc_output_nans(df_graz_met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "62f37ced-34a0-4e86-aec9-c2decefef9ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_mean(row):\n",
    "    li = row\n",
    "    li_calc = []\n",
    "    cnt = 0\n",
    "    for entry in row:\n",
    "        #print(elem)\n",
    "        if not math.isnan(entry):\n",
    "            cnt += 1\n",
    "            li_calc.append(entry)\n",
    "    #print(sum(li_calc),cnt)\n",
    "    return sum(li_calc)/cnt\n",
    "\n",
    "# only set a value if value is NaN\n",
    "def set_value_if_none(row):\n",
    "    if math.isnan(row[1]):\n",
    "        return row[0]\n",
    "    else:\n",
    "        return row[1]\n",
    "\n",
    "#apparently temp of donbosco is not a float, needs to be casted\n",
    "df_graz_met[\"d_temp\"] = pd.to_numeric(df_graz_met[\"d_temp\"])\n",
    "\n",
    "# MEAN VALUE IMPUTATION OLD\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "# # calc mean temp and set\n",
    "# df_graz_met[\"mean_temp\"] = df_graz_met[[\"d_temp\",\"n_temp\",\"s_temp\",\"w_temp\",\"e_temp\"]].apply(calc_mean,axis=1)\n",
    "# df_graz_met['e_temp'] = df_graz_met[[\"mean_temp\",\"e_temp\"]].apply(set_value_if_none,axis=1)\n",
    "# df_graz_met['n_temp'] = df_graz_met[[\"mean_temp\",\"n_temp\"]].apply(set_value_if_none,axis=1)\n",
    "# df_graz_met['s_temp'] = df_graz_met[[\"mean_temp\",\"s_temp\"]].apply(set_value_if_none,axis=1)\n",
    "# df_graz_met['w_temp'] = df_graz_met[[\"mean_temp\",\"w_temp\"]].apply(set_value_if_none,axis=1)\n",
    "# df_graz_met['d_temp'] = df_graz_met[[\"mean_temp\",\"d_temp\"]].apply(set_value_if_none,axis=1)\n",
    "\n",
    "# df_graz_met.drop(columns=[\"mean_temp\"],inplace=True)\n",
    "\n",
    "# # set pressure, only 2 stations with feature pressure, mean cannot be calculated if one is missing\n",
    "# df_graz_met['e_pressure'] = df_graz_met[[\"n_pressure\",\"e_pressure\"]].apply(set_value_if_none,axis=1)\n",
    "# df_graz_met['n_pressure'] = df_graz_met[[\"e_pressure\",\"n_pressure\"]].apply(set_value_if_none,axis=1)\n",
    "\n",
    "\n",
    "# #calc mean humidity and set\n",
    "# df_graz_met[\"mean_rh\"] = df_graz_met[[\"d_rh\",\"n_rh\",\"e_rh\",\"s_rh\",\"w_rh\"]].apply(calc_mean,axis=1)\n",
    "# df_graz_met['e_rh'] = df_graz_met[[\"mean_rh\",\"e_rh\"]].apply(set_value_if_none,axis=1)\n",
    "# df_graz_met['d_rh'] = df_graz_met[[\"mean_rh\",\"d_rh\"]].apply(set_value_if_none,axis=1)\n",
    "# df_graz_met['n_rh'] = df_graz_met[[\"mean_rh\",\"n_rh\"]].apply(set_value_if_none,axis=1)\n",
    "# df_graz_met['s_rh'] = df_graz_met[[\"mean_rh\",\"s_rh\"]].apply(set_value_if_none,axis=1)\n",
    "# df_graz_met['w_rh'] = df_graz_met[[\"mean_rh\",\"w_rh\"]].apply(set_value_if_none,axis=1)\n",
    "\n",
    "# df_graz_met.drop(columns=[\"mean_rh\"],inplace=True)\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# VALUE IMPUTATION FROM NEARBY STATION NEW \n",
    "\n",
    "\n",
    "df_graz_met['e_temp'] = df_graz_met[[\"s_temp\",\"e_temp\"]].apply(set_value_if_none,axis=1)\n",
    "df_graz_met['n_temp'] = df_graz_met[[\"w_temp\",\"n_temp\"]].apply(set_value_if_none,axis=1)\n",
    "df_graz_met['s_temp'] = df_graz_met[[\"e_temp\",\"s_temp\"]].apply(set_value_if_none,axis=1)\n",
    "df_graz_met['w_temp'] = df_graz_met[[\"d_temp\",\"w_temp\"]].apply(set_value_if_none,axis=1)\n",
    "df_graz_met['d_temp'] = df_graz_met[[\"w_temp\",\"d_temp\"]].apply(set_value_if_none,axis=1)\n",
    "\n",
    "df_graz_met['e_pressure'] = df_graz_met[[\"n_pressure\",\"e_pressure\"]].apply(set_value_if_none,axis=1)\n",
    "df_graz_met['n_pressure'] = df_graz_met[[\"e_pressure\",\"n_pressure\"]].apply(set_value_if_none,axis=1)\n",
    "\n",
    "df_graz_met['e_rh'] = df_graz_met[[\"s_rh\",\"e_rh\"]].apply(set_value_if_none,axis=1)\n",
    "df_graz_met['d_rh'] = df_graz_met[[\"w_rh\",\"d_rh\"]].apply(set_value_if_none,axis=1)\n",
    "df_graz_met['n_rh'] = df_graz_met[[\"w_rh\",\"n_rh\"]].apply(set_value_if_none,axis=1)\n",
    "df_graz_met['s_rh'] = df_graz_met[[\"e_rh\",\"s_rh\"]].apply(set_value_if_none,axis=1)\n",
    "df_graz_met['w_rh'] = df_graz_met[[\"d_rh\",\"w_rh\"]].apply(set_value_if_none,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8508dce-49a0-4be1-92cd-7e4df83390fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "calc_output_nans(df_graz_met)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e77a6e",
   "metadata": {},
   "source": [
    "# ADD PM10 LAG Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "361f4022",
   "metadata": {},
   "outputs": [],
   "source": [
    "if add_lag_values:\n",
    "    df_graz_pol[\"d_pm10Lag\"] = df_graz_pol[\"d_pm10\"].shift(1)\n",
    "    df_graz_pol[\"n_pm10Lag\"] = df_graz_pol[\"n_pm10\"].shift(1) \n",
    "    df_graz_pol[\"e_pm10Lag\"] = df_graz_pol[\"e_pm10\"].shift(1) \n",
    "    df_graz_pol[\"s_pm10Lag\"] = df_graz_pol[\"s_pm10\"].shift(1) \n",
    "    df_graz_pol[\"w_pm10Lag\"] = df_graz_pol[\"w_pm10\"].shift(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93177cc-559c-4f55-88e1-8d81d3aa11ac",
   "metadata": {},
   "source": [
    "# Drop data from 26th to 30th March (Sahara Dust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e8bf7e-f215-4273-b63a-a7d58b459562",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Sahara dust values (pollutants)\")\n",
    "display(df_graz_pol[(df_graz_pol.index >= \"2020-03-26\") & (df_graz_pol.index <= \"2020-03-30\")])\n",
    "print(\"Sahara dust values (meteorogical)\")\n",
    "display(df_graz_met[(df_graz_met.index >= \"2020-03-26\") & (df_graz_met.index <= \"2020-03-30\")])\n",
    "\n",
    "\n",
    "index_to_drop_graz = df_graz_pol[(df_graz_pol.index >= \"2020-03-26\") & (df_graz_pol.index <= \"2020-03-30\")].index\n",
    "\n",
    "if drop_graz_sahara_measurements:\n",
    "    print(\"******************************\\nDrop Sahara measurements\\n******************************\")\n",
    "    df_graz_pol.drop(index_to_drop_graz,inplace=True)\n",
    "    df_graz_met.drop(index_to_drop_graz,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7aea3b2-5636-41aa-a69f-c78f9a6662bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Drop data annually 1st to 3rd January (New year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8329ea6d-21ff-48a3-b49c-025631f474f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "li_drop_dates_new_year = ['01-01', '01-02','01-03']\n",
    "\n",
    "print(\"New year values (pollutants)\")\n",
    "display(df_graz_pol[df_graz_pol.index.strftime('%m-%d').isin(li_drop_dates_new_year)])\n",
    "\n",
    "print(\"New year values (meteorological)\")\n",
    "display(df_graz_met[df_graz_met.index.strftime('%m-%d').isin(li_drop_dates_new_year)])\n",
    "\n",
    "index_to_drop_graz = df_graz_pol[df_graz_pol.index.strftime('%m-%d').isin(li_drop_dates_new_year)].index\n",
    "\n",
    "if drop_graz_newYear_measurements:\n",
    "    print(\"******************************\\nDrop NewYear measurements\\n******************************\")\n",
    "    df_graz_met.drop(index_to_drop_graz,inplace=True)\n",
    "    df_graz_pol.drop(index_to_drop_graz,inplace=True)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6aa181-f995-4a21-b2b3-d944a528146e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Conclusion:\n",
    "### If we do not use feature e_windDirDeg,e_peakwindsp,  e_peakwindsp e_windDirClass we just have a total number of NaN values of: 303 NaNs\n",
    "### Those values cannot be imputed since they are location dependend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757c89a8-a373-493c-a510-5dde12ea6717",
   "metadata": {},
   "source": [
    "# Create seperate models (per station)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f920bd55-d94a-49aa-92a7-2249637f4550",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dict_df_stations = {'d':pd.DataFrame(),'w':pd.DataFrame(),'s':pd.DataFrame(),'n':pd.DataFrame(),'e':pd.DataFrame()}\n",
    "\n",
    "\n",
    "for key,value in dict_df_stations.items():\n",
    "    li_met_graz_col_names = [x for x in df_graz_met.keys() if x.startswith(key)] # get all column names for a station\n",
    "    li_pol_graz_col_names = [x for x in df_graz_pol.keys() if x.startswith(key)] # get all column names for a station\n",
    "    dict_df_stations[key] = pd.concat([df_graz_met[li_met_graz_col_names],df_graz_pol[li_pol_graz_col_names]],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "51735080-4e17-4f1f-9cb1-c4fd78d73a80",
   "metadata": {
    "tags": [
     "rename",
     "columns"
    ]
   },
   "outputs": [],
   "source": [
    "def rename_columns(df)->pd.DataFrame:\n",
    "    li_col_names = df.columns\n",
    "    li_new_names = [elem.split('_')[1] if len(elem.split('_'))>1 else elem for elem in li_col_names]\n",
    "    \n",
    "    dict_rename = dict(zip(li_col_names,li_new_names))\n",
    "    return  df.rename(columns=dict_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "5f5234b5-00da-425f-8af1-d7aef5018e75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key in dict_df_stations:\n",
    "    dict_df_stations[key] = rename_columns(dict_df_stations[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be06a86d-da8d-4f06-886a-d55f85aaced1",
   "metadata": {},
   "source": [
    "# Drop data annually 1st to 3rd January (New year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a796230-0dd7-46e2-8c0f-8e1b92cb131a",
   "metadata": {},
   "outputs": [],
   "source": [
    "li_drop_dates_new_year = ['01-01', '01-02','01-03']\n",
    "\n",
    "for df in dict_df_stations:  \n",
    "\n",
    "    print(\"New year values: \"+df)\n",
    "    display(dict_df_stations[df][dict_df_stations[df].index.strftime('%m-%d').isin(li_drop_dates_new_year)])\n",
    "    index_to_drop_graz = dict_df_stations[df][dict_df_stations[df].index.strftime('%m-%d').isin(li_drop_dates_new_year)].index\n",
    "\n",
    "    if drop_graz_newYear_measurements:\n",
    "        print(\"******************************\\nDrop NewYear measurements\\n******************************\")\n",
    "        dict_df_stations[df].drop(index_to_drop_graz,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ea8358-c5af-4806-ba9a-943c462576dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Add Features:\n",
    " - day of year\n",
    " - isholiday\n",
    " - dayBeforH\n",
    " - dayAfterH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f11b8bbb-69a4-4060-a22a-1a6352291616",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "for df in dict_df_stations:\n",
    "    if dayOfYearSinusFunction:  \n",
    "        dict_df_stations[df][\"dayOfYear\"] = [\n",
    "        np.sin(2 * np.pi * get_day_of_year_adjusted(date)[0] / get_day_of_year_adjusted(date)[1])\n",
    "        for date in dict_df_stations[df].index.to_pydatetime()\n",
    "                                           ]       \n",
    "    else:\n",
    "    # no sin function \n",
    "        dict_df_stations[df][\"dayOfYear\"] =  [get_day_of_year(date) for date in dict_df_stations[df].index.to_pydatetime()]\n",
    "    \n",
    "    dict_df_stations[df][\"holiday\"] =  [check_holiday(date,at_holidays) for date in dict_df_stations[df].index]\n",
    "    dict_df_stations[df][\"dayAfterHoliday\"] =  [check_holiday(date-datetime.timedelta(days=1),at_holidays) for date in dict_df_stations[df].index]\n",
    "    dict_df_stations[df][\"dayBeforeHoliday\"] =  [check_holiday(date+datetime.timedelta(days=1),at_holidays) for date in dict_df_stations[df].index]\n",
    "    dict_df_stations[df][\"weekend\"] =  [check_weekend(date) for date in dict_df_stations[df].index]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0b5202-fc83-44c4-8e14-8014a18cc477",
   "metadata": {},
   "source": [
    "# Save all stations seperately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "53003772-4bbe-43c5-b7ca-4ab3e1f88eac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for name,df in dict_df_stations.items():\n",
    "    filepath = Path('../datasets/data_per_station/'+name+'.csv')\n",
    "    dict_df_stations[name].to_csv(filepath,sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72f95de-6c54-41fb-95c2-a3f1f0f06627",
   "metadata": {},
   "source": [
    "# Save pre-processed data from Graz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ec7f2c73-8b19-46bf-8e65-8c96c18a002b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df_graz_met[\"dayOfYear\"] =  [get_day_of_year(date) for date in df_graz_met.index.to_pydatetime()]\n",
    "df_graz_met[\"g_holiday\"] =  [check_holiday(date,at_holidays) for date in df_graz_met.index]\n",
    "df_graz_met[\"g_dayAfterHoliday\"] =  [check_holiday(date-datetime.timedelta(days=1),at_holidays) for date in df_graz_met.index]\n",
    "df_graz_met[\"g_dayBeforeHoliday\"] =  [check_holiday(date+datetime.timedelta(days=1),at_holidays) for date in df_graz_met.index]\n",
    "df_graz_met[\"weekend\"] =  [check_weekend(date) for date in df_graz_met.index]\n",
    "\n",
    "filepath_graz_met_preproc = Path('../datasets/data_graz_meteorology_preprocessed.csv')\n",
    "filepath_graz_pol_preproc = Path('../datasets/data_graz_air_pollutants_preprocessed.csv')\n",
    "\n",
    "df_graz_pol.to_csv(filepath_graz_pol_preproc,sep=',') \n",
    "df_graz_met.to_csv(filepath_graz_met_preproc,sep=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80840414-9418-4294-a2ff-bc89c76c3771",
   "metadata": {},
   "outputs": [],
   "source": [
    "date = datetime.date(2020,12,31)\n",
    "print(check_holiday(date+datetime.timedelta(days=1),at_holidays))\n",
    "print(check_holiday(date-datetime.timedelta(days=1),at_holidays))\n",
    "print(check_holiday(date,at_holidays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db51bb3-ca4a-42dd-bd09-a6c37c452c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PMForecastingVenV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
